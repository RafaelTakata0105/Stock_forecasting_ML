{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88473be1",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Proyect 2 - Stock Forecasting with RNNs, LSTMs and GRU</h1>\n",
    "\n",
    "<h4 style=\"text-align: center;\">\n",
    "\n",
    "Roi Jared Flores Garza Stone\n",
    "\n",
    "Esteban Gomez Valerio\n",
    "\n",
    "Ivan Morales Camacho\n",
    "\n",
    "Rafael Takata Garcia\n",
    "\n",
    "Machine Learning - O2025_MAF3654H\n",
    "\n",
    "Ing. Juan Antonio Vega Fernández, M. Sc., M. T. Ed\n",
    "\n",
    "ITESO\n",
    "</h4>\n",
    "\n",
    "---\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Financial markets are inherently complex, noisy, and non-linear systems, making accurate forecasting of asset prices one of the most challenging and valuable problems in quantitative finance. The ability to predict future stock prices or returns, even over a short horizon, is crucial for developing profitable trading strategies, managing risk, and optimizing investment portfolios.\n",
    "\n",
    "Traditional time series models, such as ARIMA (Autoregressive Integrated Moving Average), rely on strict statistical assumptions (like linearity and stationarity) that often fail to capture the subtle, long-range temporal dependencies and complex non-linear dynamics inherent in high-frequency financial data.\n",
    "\n",
    "### Objective\n",
    "\n",
    "This Jupyter Notebook aims to address these challenges by employing modern Recurrent Neural Network (RNN) architectures, specifically Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU). In this case, we will use the \n",
    "\n",
    "---\n",
    "\n",
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70143730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from collections import defaultdict\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance\n",
    "#!pip install scikit-learn\n",
    "#!pip install seaborn\n",
    "!pip install mplfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08931a72",
   "metadata": {},
   "source": [
    "### Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"ORCL\"\n",
    "data_ticker = yf.Ticker(symbol)\n",
    "data = data_ticker.history(period=\"3mo\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "start_date = \"2010-01-01\"\n",
    "\n",
    "df = yf.download('ORCL', start=start_date, end=end_date)\n",
    "\n",
    "df.columns = df.columns.droplevel()\n",
    "df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84de5ca",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43653975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def data_plotter(df):\n",
    "    df_plot = df.copy()\n",
    "    ncols = 2\n",
    "    nrows = int(round(df_plot.shape[1] / ncols, 0))\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(14, 7))\n",
    "\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        sns.lineplot(data=df_plot.iloc[:, i], ax=ax)\n",
    "        ax.tick_params(axis=\"x\", rotation=30, labelsize=10, length=0)\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    fig.tight_layout()\n",
    "    plt.show\n",
    "\n",
    "data_plotter(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f800b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "\n",
    "# Select the last 180 trading days for visualization (approx 6-9 months)\n",
    "df_candlestick = df.tail(60).copy()\n",
    "\n",
    "mpf.plot(\n",
    "    df_candlestick,\n",
    "    type='ohlc',\n",
    "    style='yahoo',\n",
    "    volume=True,\n",
    "    title='ORCL Candlestick Chart (Last 180 Trading Days)',\n",
    "    ylabel='Price (USD)',\n",
    "    ylabel_lower='Volume',\n",
    "    figsize=(14, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7de9a",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "Here we are going to use MinMaxScaler from sklearn in order to help the NNs to converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afdeb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Train test split\n",
    "training_data_len = math.ceil(len(df) * .8)\n",
    "print(f\"The training dataset consists of {training_data_len} instances\")\n",
    "\n",
    "# Splitting the dataset\n",
    "train_data = df[:training_data_len].iloc[:, :1]\n",
    "test_data = df[training_data_len:].iloc[:, :1]\n",
    "\n",
    "# Selecting Open Price values\n",
    "dataset_train = train_data.Open.values\n",
    "# Reshaping 1D to 2D array\n",
    "dataset_train = np.reshape(dataset_train, (-1, 1))\n",
    "print(f\"Training shape is: {dataset_train.shape}\")\n",
    "\n",
    "# Selecting Open Price values\n",
    "dataset_test = test_data.Open.values\n",
    "# Reshaping 1D to 2D array\n",
    "dataset_test = np.reshape(dataset_test, (-1, 1))\n",
    "print(f\"Test shape is: {dataset_test.shape}\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# Scaling dataset\n",
    "scaled_train = scaler.fit_transform(dataset_train)\n",
    "print(scaled_train[:5])\n",
    "\n",
    "# Normalizing values between 0 and 1\n",
    "scaled_test = scaler.fit_transform(dataset_test)\n",
    "print(scaled_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff039d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences and labels for training data\n",
    "sequence_length = 50  # Number of time steps to look back\n",
    "X_train, y_train = [], []\n",
    "for i in range(len(scaled_train) - sequence_length):\n",
    "    X_train.append(scaled_train[i:i + sequence_length])\n",
    "    y_train.append(scaled_train[i + sequence_length])  # Predicting the value right after the sequence\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Create sequences and labels for testing data\n",
    "sequence_length = 30  # Number of time steps to look back\n",
    "X_test, y_test = [], []\n",
    "for i in range(len(scaled_test) - sequence_length):\n",
    "    X_test.append(scaled_test[i:i + sequence_length])\n",
    "    y_test.append(scaled_test[i + sequence_length])  # Predicting the value right after the sequence\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432eca3",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6945884",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "input_size = 1\n",
    "num_layers = 3  # Increased number of layers\n",
    "hidden_size = 128  # Increased number of hidden units\n",
    "output_size = 1\n",
    "dropout = 0.2  # Added dropout for regularization\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, dropout).to(device)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # Learning rate\n",
    "\n",
    "batch_size = 32  # Adjusted batch size\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 100  # Increased number of epochs\n",
    "train_hist = []\n",
    "test_hist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        predictions = model(batch_X)\n",
    "        loss = loss_fn(predictions, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_hist.append(average_loss)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0.0\n",
    "\n",
    "        for batch_X_test, batch_y_test in test_loader:\n",
    "            batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
    "            predictions_test = model(batch_X_test)\n",
    "            test_loss = loss_fn(predictions_test, batch_y_test)\n",
    "\n",
    "            total_test_loss += test_loss.item()\n",
    "\n",
    "        average_test_loss = total_test_loss / len(test_loader)\n",
    "        test_hist.append(average_test_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,num_epochs,num_epochs)\n",
    "plt.plot(x,train_hist,scalex=True, label=\"Training loss\")\n",
    "plt.plot(x, test_hist, label=\"Test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddaaa61",
   "metadata": {},
   "source": [
    "## Forecasting with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b356f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_forecast_steps = 30\n",
    "sequence_to_plot = X_test.squeeze().cpu().numpy()\n",
    "historical_data = sequence_to_plot[-1]\n",
    "\n",
    "forecasted_values = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_forecast_steps):\n",
    "        historical_data_tensor = torch.as_tensor(historical_data).view(1, -1, 1).float().to(device)\n",
    "        predicted_value = model(historical_data_tensor).cpu().numpy()[0, 0]\n",
    "        forecasted_values.append(predicted_value)\n",
    "        historical_data = np.roll(historical_data, shift=-1)\n",
    "        historical_data[-1] = predicted_value\n",
    "\n",
    "last_date = test_data.index[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.DateOffset(1), periods=30)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14, 4]\n",
    "plt.plot(test_data.index[-100:], test_data.Open[-100:], label=\"test_data\", color=\"b\")\n",
    "plt.plot(test_data.index[-30:], test_data.Open[-30:], label='actual values', color='green')\n",
    "plt.plot(test_data.index[-1:].append(future_dates), np.concatenate([test_data.Open[-1:], scaler.inverse_transform(np.array(forecasted_values).reshape(-1, 1)).flatten()]), label='forecasted values', color='red')\n",
    "\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.title('Time Series Forecasting')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model and calculate RMSE and R² score\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = []\n",
    "    for batch_X_test in X_test:\n",
    "        batch_X_test = batch_X_test.to(device).unsqueeze(0)  # Add batch dimension\n",
    "        test_predictions.append(model(batch_X_test).cpu().numpy().flatten()[0])\n",
    "\n",
    "test_predictions = np.array(test_predictions)\n",
    "\n",
    "# Calculate RMSE and R² score\n",
    "rmse = np.sqrt(mean_squared_error(y_test.cpu().numpy(), test_predictions))\n",
    "r2 = r2_score(y_test.cpu().numpy(), test_predictions)\n",
    "\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R² Score: {r2:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NST_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
